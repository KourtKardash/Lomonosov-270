# Lomonosov-270

Данный репозиторий содержит инструкцию к запуску кода на кластере Ломоносов-270.
В качестве примера взят мини-проект, с описанием которого можно ознакомиться по [ссылке](https://vkvideo.ru/video-227335000_456239038?t=59s).

Работа с кластером начинается на сторонней машине. Код, запускающий обучение, необходимо упаковать в Docker. Пример [Docker-файла](https://github.com/KourtKardash/Lomonosov-270/blob/main/TestDocker/Dockerfile).
Команда сбора образа текущего проекта:

```bash
docker build -t cell-segmentation .
```
Рекомендуется поднять контейнер и убедиться, что обучение успешно запускается. Все необходимые файлы для запуска контейнера с текущим проектом содержатся в папке [TestDocker](https://github.com/KourtKardash/Lomonosov-270/tree/main/TestDocker).

На кластере используется Slurm — это система управления заданиями, которая распределяет вычислительные задачи по узлам кластера и контролирует использование ресурсов. 
Для работы с контейнерами Slurm использует enroot, поэтому необходимо перевести образ в удобный для него формат (.sqsh). Команда для текущего проекта:

```bash
enroot import -o noisy-cells.sqsh dockerd://cell-segmentation:latest
```

Переносим готовый .sqsh образ на кластер.

---

Файлы в папке [TestSlurm](https://github.com/KourtKardash/Lomonosov-270/tree/main/TestSlurm) содержат примеры запуска обучения на кластере. Файл script.sh позволит запустить обучение одной модели. Файл parallel_train.py позволит запустить несколько обучений параллельно. В данном примере запускается одна и та же модель 3 раза, но на практике можно запускать разные файлы или запускать одну модель, передавая разные параметры.

---

### Команды Slurm

Запуск обучения:
```bash
srun --gres=gpu:1 --mem=20G --container-image /scratch/s02210430/test/noisy-cells.sqsh --container-mounts /scratch/s02210430/test/data:/workspace/data bash -c 'python3 code/nn.py' > output.log 2>&1
```
**Путь к образу обязательно должен быть абсолютным!**
- --gres=gpu:1 выделяет 1 GPU для задачи.
- --mem=20G выделяет 20 гигабайт оперативной памяти на весь узел для выполнения задания.

  Другие флаги:
- --nodes=1 - будет использоваться ровно 1 узел.
- --time=3-01:00:00 - лимит времени, 3 дня и 1 час
- -w cn23 - задает конкретную ноду (cn23 - название ноды).

`sinfo -N` - показывает общий список нод и состояние каждой.

`squeue` - команда для просмотра состояния задач.
